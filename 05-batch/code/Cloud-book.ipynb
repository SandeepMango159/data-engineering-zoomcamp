{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "979d8f74",
   "metadata": {},
   "source": [
    "# This notebook is for creating a master spark cluster and connecting to GCS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0fc31d",
   "metadata": {},
   "source": [
    "## Setup spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25df6f0",
   "metadata": {},
   "source": [
    "### Setup python environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d193c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Sandeep SSD\\Programming SSD\\Data Engineering Zoomcamp\\data-engineering-zoomcamp\\dataenginzoomvenv\\Scripts\\python.exe\n",
      "c:\\Sandeep SSD\\Programming SSD\\Data Engineering Zoomcamp\\data-engineering-zoomcamp\\dataenginzoomvenv\\Scripts\\python.exe\n",
      "c:\\Sandeep SSD\\Programming SSD\\Data Engineering Zoomcamp\\data-engineering-zoomcamp\\dataenginzoomvenv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# Add the vevn to spark's settings, so inject the venvâ€™s Python into both driver & worker configs before recreating the session, to find the right python interpreter, since the notebook us running within the venv kernel, we can just use sys.executable\n",
    "import os, sys\n",
    "\n",
    "print(sys.executable)\n",
    "venv_python = sys.executable\n",
    "\n",
    "# 1) Ensure the worker uses exactly this Python executable:\n",
    "os.environ['PYSPARK_PYTHON'] = venv_python\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = venv_python\n",
    "\n",
    "print(os.environ['PYSPARK_PYTHON'])\n",
    "print(os.environ['PYSPARK_DRIVER_PYTHON'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd70afbf",
   "metadata": {},
   "source": [
    "### Launch spark with those python variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3307b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://192.168.0.181:7077\") \\\n",
    "    .appName('test') \\\n",
    "    .config(\"spark.pyspark.python\", venv_python) \\\n",
    "    .config(\"spark.pyspark.driver.python\", venv_python) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "610785cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://192.168.0.181:4041\n"
     ]
    }
   ],
   "source": [
    "# Check which port the Spark UI is running on\n",
    "print(spark.sparkContext.uiWebUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.181:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://192.168.0.181:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1ad7f41d3d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print spark to show all the spark info\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6a44cb",
   "metadata": {},
   "source": [
    "## Testing the cluster by reading files and writing, same as book 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa423837",
   "metadata": {},
   "source": [
    "### Read green files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ee1eb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 2 * since we have year subfolders, and month subfolders, okay...\n",
    "df_green = spark.read.parquet('../../Data/data/csv/green/spark_parquet/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ca5ee99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "|VendorID|lpep_pickup_datetime|lpep_dropoff_datetime|store_and_fwd_flag|RatecodeID|PULocationID|DOLocationID|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|ehail_fee|improvement_surcharge|total_amount|payment_type|trip_type|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "|       2| 2020-01-12 18:15:04|  2020-01-12 18:19:52|                 N|         1|          41|          41|              1|         0.78|        5.5|  0.0|    0.5|      1.58|         0.0|     null|                  0.3|        7.88|           1|        1|                 0.0|\n",
      "|       2| 2020-01-31 20:24:10|  2020-01-31 20:31:51|                 N|         1|         173|          70|              1|         0.98|        7.0|  0.5|    0.5|       0.0|         0.0|     null|                  0.3|         8.3|           2|        1|                 0.0|\n",
      "|       2| 2020-01-07 08:16:53|  2020-01-07 08:41:39|                 N|         1|          74|         236|              1|          2.7|       16.0|  0.0|    0.5|      3.91|         0.0|     null|                  0.3|       23.46|           1|        1|                2.75|\n",
      "|       1| 2020-01-15 14:47:15|  2020-01-15 14:54:34|                 N|         1|          25|          66|              1|          0.8|        6.5|  0.0|    0.5|       0.0|         0.0|     null|                  0.3|         7.3|           2|        1|                 0.0|\n",
      "|    null| 2020-01-31 10:08:00|  2020-01-31 10:20:00|              null|      null|         259|          51|           null|         2.33|      22.49| 2.75|    0.0|       0.0|         0.0|     null|                  0.3|       25.54|        null|     null|                null|\n",
      "|       2| 2020-01-18 17:46:45|  2020-01-18 18:04:08|                 N|         1|         177|         188|              1|         2.62|       12.5|  0.0|    0.5|       0.0|         0.0|     null|                  0.3|        13.3|           1|        1|                 0.0|\n",
      "|       2| 2020-01-17 20:08:44|  2020-01-17 20:18:47|                 N|         1|          65|          97|              1|         1.13|        8.0|  0.5|    0.5|      1.86|         0.0|     null|                  0.3|       11.16|           1|        1|                 0.0|\n",
      "|    null| 2020-01-13 10:47:00|  2020-01-13 10:54:00|              null|      null|         165|         123|           null|         1.36|      17.51| 2.75|    0.0|       0.0|         0.0|     null|                  0.3|       20.56|        null|     null|                null|\n",
      "|    null| 2020-01-07 15:36:00|  2020-01-07 16:11:00|              null|      null|         170|         220|           null|        11.15|       46.0| 2.75|    0.0|       0.0|         0.0|     null|                  0.3|       49.05|        null|     null|                null|\n",
      "|    null| 2020-01-10 11:47:00|  2020-01-10 12:03:00|              null|      null|          74|          41|           null|         1.78|       8.76|  0.0|    0.5|       0.0|         0.0|     null|                  0.3|        9.56|        null|     null|                null|\n",
      "|       1| 2020-01-08 20:17:48|  2020-01-08 20:23:24|                 Y|         1|          75|          41|              1|          1.0|        6.0|  0.5|    0.5|       0.0|         0.0|     null|                  0.3|         7.3|           2|        1|                 0.0|\n",
      "|       2| 2020-01-28 10:57:21|  2020-01-28 11:15:13|                 N|         1|          74|         151|              1|         2.75|       13.5|  0.0|    0.5|      2.86|         0.0|     null|                  0.3|       17.16|           1|        1|                 0.0|\n",
      "|       1| 2020-01-16 18:02:21|  2020-01-16 18:11:21|                 N|         1|          41|          74|              1|          1.1|        7.5|  1.0|    0.5|       2.3|         0.0|     null|                  0.3|        11.6|           1|        1|                 0.0|\n",
      "|       2| 2020-01-07 14:03:38|  2020-01-07 14:17:02|                 N|         1|         116|          74|              1|         3.81|       13.5|  0.0|    0.5|       0.0|         0.0|     null|                  0.3|        14.3|           2|        1|                 0.0|\n",
      "|       2| 2020-01-14 09:52:46|  2020-01-14 10:06:41|                 N|         1|         152|         244|              1|         1.85|       11.0|  0.0|    0.5|       0.0|         0.0|     null|                  0.3|        11.8|           1|        1|                 0.0|\n",
      "|    null| 2020-01-23 05:40:00|  2020-01-23 06:13:00|              null|      null|          71|          88|           null|         9.14|      30.99| 2.75|    0.0|       0.0|         0.0|     null|                  0.3|       34.04|        null|     null|                null|\n",
      "|       2| 2020-01-23 10:17:52|  2020-01-23 10:24:02|                 N|         1|          43|         236|              1|         1.04|        6.0|  0.0|    0.5|       0.0|         0.0|     null|                  0.3|        9.55|           2|        1|                2.75|\n",
      "|       2| 2020-01-09 21:09:46|  2020-01-09 21:14:35|                 N|         1|          65|          49|              1|         1.14|        5.5|  0.5|    0.5|       1.2|         0.0|     null|                  0.3|         8.0|           1|        1|                 0.0|\n",
      "|    null| 2020-01-08 20:53:00|  2020-01-08 21:00:00|              null|      null|         254|         254|           null|         1.15|        8.0|  0.0|    0.0|       0.0|         0.0|     null|                  0.3|         8.3|        null|     null|                null|\n",
      "|       2| 2020-01-02 09:04:51|  2020-01-02 09:11:18|                 N|         1|         116|         244|              1|         0.92|        6.0|  0.0|    0.0|       0.0|         0.0|     null|                  0.0|         6.0|           2|        2|                 0.0|\n",
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# After reading the green parquet files, we show them\n",
    "df_green.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d714689b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2304517"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "149bdae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('VendorID', IntegerType(), True), StructField('lpep_pickup_datetime', TimestampType(), True), StructField('lpep_dropoff_datetime', TimestampType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('RatecodeID', IntegerType(), True), StructField('PULocationID', IntegerType(), True), StructField('DOLocationID', IntegerType(), True), StructField('passenger_count', IntegerType(), True), StructField('trip_distance', DoubleType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('ehail_fee', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('payment_type', IntegerType(), True), StructField('trip_type', IntegerType(), True), StructField('congestion_surcharge', DoubleType(), True)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the schemas, make sure it's the same as the one that we wrote to the parquet file\n",
    "df_green.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27ee0afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- lpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- lpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- ehail_fee: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- trip_type: integer (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "649bb4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to make it easier to read\n",
    "df_green = df_green \\\n",
    "    .withColumnRenamed('lpep_pickup_datetime', 'pickup_datetime') \\\n",
    "    .withColumnRenamed('lpep_dropoff_datetime', 'dropoff_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9034e1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- ehail_fee: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- trip_type: integer (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show to make sure columns got renamed\n",
    "df_green.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff13f4ae",
   "metadata": {},
   "source": [
    "### Read yellow files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90cd6845",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow = spark.read.parquet('../../Data/data/csv/yellow/spark_parquet/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51f8b867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|       2| 2020-01-16 13:25:44|  2020-01-16 13:38:16|              1|         1.88|         1|                 N|         239|         263|           1|       10.0|  0.0|    0.5|      3.33|         0.0|                  0.3|       16.63|                 2.5|\n",
      "|       2| 2020-01-18 12:37:08|  2020-01-18 12:49:16|              1|         2.05|         1|                 N|         162|          79|           2|        9.5|  0.0|    0.5|       0.0|         0.0|                  0.3|        12.8|                 2.5|\n",
      "|       1| 2020-01-15 21:39:18|  2020-01-15 21:45:44|              2|          1.4|         1|                 N|         230|         142|           1|        7.0|  3.0|    0.5|       1.0|         0.0|                  0.3|        11.8|                 2.5|\n",
      "|       1| 2020-01-15 19:42:58|  2020-01-15 19:58:28|              1|          2.4|         1|                 N|         162|         143|           1|       12.0|  3.5|    0.5|      2.45|         0.0|                  0.3|       18.75|                 2.5|\n",
      "|       1| 2020-01-27 18:52:54|  2020-01-27 19:04:53|              1|          1.7|         1|                 N|         161|         236|           1|        9.5|  3.5|    0.5|      2.75|         0.0|                  0.3|       16.55|                 2.5|\n",
      "|       2| 2020-01-14 14:48:15|  2020-01-14 15:04:26|              1|         2.24|         1|                 N|         141|         239|           2|       12.0|  0.0|    0.5|       0.0|         0.0|                  0.3|        15.3|                 2.5|\n",
      "|       2| 2020-01-18 01:20:56|  2020-01-18 01:24:41|              5|         0.73|         1|                 N|         170|         137|           1|        5.0|  0.5|    0.5|      1.76|         0.0|                  0.3|       10.56|                 2.5|\n",
      "|       1| 2020-01-24 20:57:00|  2020-01-24 21:06:04|              1|          1.1|         1|                 N|         100|         233|           1|        7.5|  3.0|    0.5|       1.0|         0.0|                  0.3|        12.3|                 2.5|\n",
      "|       2| 2020-01-06 12:36:37|  2020-01-06 12:46:25|              1|         2.17|         1|                 N|         163|         238|           1|        9.5|  0.0|    0.5|       1.2|         0.0|                  0.3|        14.0|                 2.5|\n",
      "|       2| 2020-01-01 01:11:43|  2020-01-01 01:30:27|              1|         3.46|         1|                 N|         236|         164|           1|       15.0|  0.5|    0.5|      3.76|         0.0|                  0.3|       22.56|                 2.5|\n",
      "|       2| 2020-01-20 09:55:33|  2020-01-20 09:58:12|              5|         0.25|         1|                 N|         229|         229|           1|        3.5|  0.0|    0.5|       3.0|         0.0|                  0.3|         9.8|                 2.5|\n",
      "|       1| 2020-01-13 08:33:54|  2020-01-13 08:44:19|              1|          1.1|         1|                 N|         237|         161|           1|        8.0|  2.5|    0.5|       1.7|         0.0|                  0.3|        13.0|                 2.5|\n",
      "|       2| 2020-01-04 19:47:47|  2020-01-04 19:49:43|              2|         0.42|         1|                 N|          90|          90|           1|        3.5|  0.0|    0.5|       1.5|         0.0|                  0.3|         8.3|                 2.5|\n",
      "|       2| 2020-01-28 14:33:48|  2020-01-28 14:44:17|              1|         1.38|         1|                 N|         239|         142|           2|        8.5|  0.0|    0.5|       0.0|         0.0|                  0.3|        11.8|                 2.5|\n",
      "|       1| 2020-01-24 22:26:54|  2020-01-24 22:35:55|              1|          0.9|         1|                 N|         234|          79|           1|        7.0|  3.0|    0.5|       2.0|         0.0|                  0.3|        12.8|                 2.5|\n",
      "|       2| 2020-01-21 20:20:24|  2020-01-21 20:30:23|              1|         1.94|         1|                 N|         170|          90|           1|        8.5|  0.5|    0.5|      2.46|         0.0|                  0.3|       14.76|                 2.5|\n",
      "|       2| 2020-01-16 14:23:08|  2020-01-16 14:34:59|              1|         1.02|         1|                 N|         161|         100|           1|        8.5|  0.0|    0.5|      2.36|         0.0|                  0.3|       14.16|                 2.5|\n",
      "|       2| 2020-01-18 12:48:42|  2020-01-18 12:59:32|              1|         1.67|         1|                 N|         164|         246|           1|        8.5|  0.0|    0.5|      1.77|         0.0|                  0.3|       13.57|                 2.5|\n",
      "|       1| 2020-01-27 16:58:41|  2020-01-27 17:02:06|              2|          0.5|         1|                 N|         234|          90|           1|        4.0|  3.5|    0.5|      1.65|         0.0|                  0.3|        9.95|                 2.5|\n",
      "|       2| 2020-01-11 10:16:52|  2020-01-11 10:24:51|              1|         1.06|         1|                 N|          79|         211|           1|        7.0|  0.0|    0.5|      2.06|         0.0|                  0.3|       12.36|                 2.5|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# After reading the green parquet files, we show them\n",
    "df_yellow.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6947a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39649199"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count just to make sure it's right\n",
    "df_yellow.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f006adde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('VendorID', IntegerType(), True), StructField('tpep_pickup_datetime', TimestampType(), True), StructField('tpep_dropoff_datetime', TimestampType(), True), StructField('passenger_count', IntegerType(), True), StructField('trip_distance', DoubleType(), True), StructField('RatecodeID', IntegerType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('PULocationID', IntegerType(), True), StructField('DOLocationID', IntegerType(), True), StructField('payment_type', IntegerType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the schemas, make sure it's the same as the one that we wrote to the parquet file\n",
    "df_yellow.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e689affe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_yellow.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88822efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to make it easier to read, and also join with the green schema data\n",
    "df_yellow = df_yellow \\\n",
    "    .withColumnRenamed('tpep_pickup_datetime', 'pickup_datetime') \\\n",
    "    .withColumnRenamed('tpep_dropoff_datetime', 'dropoff_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81f978ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show to make sure columns got renamed\n",
    "df_yellow.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f796a3e",
   "metadata": {},
   "source": [
    "### Joining both dataframes together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8605148a",
   "metadata": {},
   "source": [
    "#### Each dataframe has a columns field, which we can use to get the columns that both dataframes have in common, meaning which ones exist in both dataframes\n",
    "##### We have already renamed the pickup and dropoffdatetime columns for both dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b230019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'store_and_fwd_flag',\n",
       " 'RatecodeID',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'ehail_fee',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'payment_type',\n",
       " 'trip_type',\n",
       " 'congestion_surcharge']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "610167a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we'll write a small function for that, that holds a common columns list\n",
    "# Puts the columns of yellow into a list\n",
    "# And iterate over the green columns, if they're also in the yellow columns set, we'll add them to the list\n",
    "# This way preserves the order of columns as defined by the spark dataframe when reading the parquet files\n",
    "common_colums = []\n",
    "\n",
    "yellow_columns = set(df_yellow.columns)\n",
    "\n",
    "for col in df_green.columns:\n",
    "    if col in yellow_columns:\n",
    "        common_colums.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "999a5421",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_colums = [\n",
    "'VendorID',\n",
    " 'pickup_datetime',\n",
    " 'dropoff_datetime',\n",
    " 'store_and_fwd_flag',\n",
    " 'RatecodeID',\n",
    " 'PULocationID',\n",
    " 'DOLocationID',\n",
    " 'passenger_count',\n",
    " 'trip_distance',\n",
    " 'fare_amount',\n",
    " 'extra',\n",
    " 'mta_tax',\n",
    " 'tip_amount',\n",
    " 'tolls_amount',\n",
    " 'improvement_surcharge',\n",
    " 'total_amount',\n",
    " 'payment_type',\n",
    " 'congestion_surcharge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "839d773f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2498810a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[VendorID: int, pickup_datetime: timestamp, dropoff_datetime: timestamp, store_and_fwd_flag: string, RatecodeID: int, PULocationID: int, DOLocationID: int, passenger_count: int, trip_distance: double, fare_amount: double, extra: double, mta_tax: double, tip_amount: double, tolls_amount: double, improvement_surcharge: double, total_amount: double, payment_type: int, congestion_surcharge: double, service_type: string]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using select we can select the list of common columns, \n",
    "# We'll also add a service type to distinguish where they come from\n",
    "# F.lit for literal\n",
    "df_green_sel = df_green \\\n",
    "    .select(common_colums) \\\n",
    "    .withColumn('service_type', F.lit('green'))\n",
    "\n",
    "# Print to make sure it works\n",
    "df_green_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19032efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[VendorID: int, pickup_datetime: timestamp, dropoff_datetime: timestamp, store_and_fwd_flag: string, RatecodeID: int, PULocationID: int, DOLocationID: int, passenger_count: int, trip_distance: double, fare_amount: double, extra: double, mta_tax: double, tip_amount: double, tolls_amount: double, improvement_surcharge: double, total_amount: double, payment_type: int, congestion_surcharge: double, service_type: string]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same for this yellow dataframe\n",
    "df_yellow_sel = df_yellow \\\n",
    "    .select(common_colums) \\\n",
    "    .withColumn('service_type', F.lit('yellow'))\n",
    "\n",
    "df_yellow_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5b0f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join them together\n",
    "df_trips_data = df_green_sel.unionAll(df_yellow_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d96d28fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'store_and_fwd_flag',\n",
       " 'RatecodeID',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'payment_type',\n",
       " 'congestion_surcharge',\n",
       " 'service_type']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all the columns again\n",
    "df_trips_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bed8b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|service_type|   count|\n",
      "+------------+--------+\n",
      "|       green| 2304517|\n",
      "|      yellow|39649199|\n",
      "+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count the rows by grouping by service type to make sure they're the same as before \n",
    "df_trips_data.groupBy('service_type').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c846bcc",
   "metadata": {},
   "source": [
    "### Writing the SQL code for spark dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a91d70c",
   "metadata": {},
   "source": [
    "##### First we have to be able to use the dataframe, we do that by registering it as a table, otherwise SQL statements won't work on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36e90cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a table for it, but this method is deprecated so use the new method below\n",
    "# df_trips_data.registerTempTable('trips_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e619b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The new suggested method to use instead\n",
    "df_trips_data.createOrReplaceTempView('trips_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0e01bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|service_type|count(1)|\n",
      "+------------+--------+\n",
      "|       green| 2304517|\n",
      "|      yellow|39649199|\n",
      "+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now we can write sql and access that dataframe by the table name, results are the same as above\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    service_type,\n",
    "    count(1)\n",
    "FROM\n",
    "    trips_data\n",
    "GROUP BY \n",
    "    service_type\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e132449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the same query from week 4, for dm_monthly_zone_revenue\n",
    "\n",
    "df_result = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    -- Revenue grouping \n",
    "    PULocationID AS revenue_zone,\n",
    "    date_trunc('month', pickup_datetime) AS revenue_month, \n",
    "    service_type, \n",
    "\n",
    "    -- Revenue calculation \n",
    "    SUM(fare_amount) AS revenue_monthly_fare,\n",
    "    SUM(extra) AS revenue_monthly_extra,\n",
    "    SUM(mta_tax) AS revenue_monthly_mta_tax,\n",
    "    SUM(tip_amount) AS revenue_monthly_tip_amount,\n",
    "    SUM(tolls_amount) AS revenue_monthly_tolls_amount,\n",
    "    SUM(improvement_surcharge) AS revenue_monthly_improvement_surcharge,\n",
    "    SUM(total_amount) AS revenue_monthly_total_amount,\n",
    "    SUM(congestion_surcharge) AS revenue_monthly_congestion_surcharge,\n",
    "\n",
    "    -- Additional calculations\n",
    "    AVG(passenger_count) AS avg_monthly_passenger_count,\n",
    "    AVG(trip_distance) AS avg_monthly_trip_distance\n",
    "FROM\n",
    "    trips_data\n",
    "GROUP BY\n",
    "    1, 2, 3\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f86c90f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+------------+--------------------+---------------------+-----------------------+--------------------------+----------------------------+-------------------------------------+----------------------------+------------------------------------+---------------------------+-------------------------+\n",
      "|revenue_zone|      revenue_month|service_type|revenue_monthly_fare|revenue_monthly_extra|revenue_monthly_mta_tax|revenue_monthly_tip_amount|revenue_monthly_tolls_amount|revenue_monthly_improvement_surcharge|revenue_monthly_total_amount|revenue_monthly_congestion_surcharge|avg_monthly_passenger_count|avg_monthly_trip_distance|\n",
      "+------------+-------------------+------------+--------------------+---------------------+-----------------------+--------------------------+----------------------------+-------------------------------------+----------------------------+------------------------------------+---------------------------+-------------------------+\n",
      "|          47|2020-01-01 00:00:00|       green|  16630.150000000023|               1192.0|                  160.0|        42.230000000000004|           523.0000000000002|                   210.90000000000015|          18770.429999999975|                                11.0|          1.177685950413223|        4.645000000000002|\n",
      "|          53|2020-01-01 00:00:00|       green|   6281.649999999996|               330.25|                   49.0|                     39.22|          102.50000000000001|                    68.39999999999988|           6873.770000000004|                                2.75|         1.2417582417582418|        6.929710743801654|\n",
      "|         128|2020-01-01 00:00:00|       green|   3261.330000000001|                158.0|                   35.5|                     82.25|          104.03999999999999|                    34.50000000000004|          3714.0200000000004|                                27.5|         1.0169491525423728|        7.023280000000001|\n",
      "|         150|2020-01-01 00:00:00|       green|             9996.16|                627.5|                   98.0|         97.86999999999998|                      149.14|                   109.49999999999962|          11082.069999999992|                                 0.0|         1.1147540983606556|        5.393588516746414|\n",
      "|         263|2020-01-01 00:00:00|       green|   8987.339999999998|                561.0|                 124.55|                    315.27|           335.0600000000001|                    127.1999999999995|          10684.170000000004|                              239.25|         1.4293478260869565|        5.264249422632793|\n",
      "|          19|2020-01-01 00:00:00|       green|   7798.879999999999|                377.0|                   42.0|                      6.66|          174.40000000000003|                     67.4999999999999|           8466.440000000004|                                 0.0|                   1.046875|        7.850781893004114|\n",
      "|         186|2020-01-01 00:00:00|       green|             1539.23|                85.25|                    6.0|                       0.0|           97.91999999999999|                                 13.8|          1742.1999999999998|                                 0.0|         1.6666666666666667|        9.389565217391304|\n",
      "|         238|2020-01-01 00:00:00|       green|   5397.990000000001|                403.5|                   20.0|                       0.0|                      124.68|                    61.19999999999993|           6007.370000000001|                                 0.0|                        1.2|        6.460536585365853|\n",
      "|         126|2020-01-01 00:00:00|       green|   11827.83999999999|               766.75|                  110.5|        101.86999999999999|           458.2800000000002|                   145.19999999999933|          13425.340000000004|                                11.0|                      1.275|        5.187806691449811|\n",
      "|          96|2020-01-01 00:00:00|       green|   628.8000000000001|                 27.5|                    4.0|                       0.0|                       55.08|                    5.699999999999999|           721.0799999999999|                                 0.0|         1.1428571428571428|       7.0195454545454545|\n",
      "|         116|2020-01-01 00:00:00|       green|   78706.70999999996|              3319.25|                 2632.5|         5847.950000000004|          1467.9299999999985|                   1756.4999999999027|           96138.29000000306|                              2793.0|          1.212485896953742|        3.068908940397343|\n",
      "|          90|2020-01-01 00:00:00|       green|             2921.62|                165.0|                   19.0|                       0.0|          190.56000000000006|                   25.800000000000022|          3321.9800000000005|                                 0.0|                        1.2|        8.451627906976745|\n",
      "|         101|2020-01-01 00:00:00|       green|   8472.769999999997|                460.5|                   38.0|        15.219999999999999|          232.56000000000006|                    70.49999999999986|           9289.550000000001|                                2.75|         1.0512820512820513|        9.081153846153853|\n",
      "|         227|2020-01-01 00:00:00|       green|  14857.100000000011|               776.75|                   94.5|        21.569999999999997|          271.57000000000005|                   137.09999999999937|          16173.289999999986|                                 0.0|         1.0743801652892562|        7.235522088353416|\n",
      "|         180|2020-01-01 00:00:00|       green|  4024.4600000000005|               210.75|                   26.0|                     20.24|           84.88999999999999|                    43.20000000000006|           4414.240000000002|                                2.75|         1.3396226415094339|        5.324473684210526|\n",
      "|         190|2020-01-01 00:00:00|       green|  3786.0199999999995|                175.0|                   76.5|        242.16000000000008|                       24.48|                    62.69999999999993|           4419.360000000001|                               35.75|         1.4244604316546763|       3.5506912442396326|\n",
      "|         264|2008-12-01 00:00:00|       green|                 0.0|                  0.0|                    0.0|                       0.0|                         0.0|                                  0.0|                         0.0|                                 0.0|                        1.0|                      0.0|\n",
      "|         119|2020-01-01 00:00:00|       green|  21224.650000000012|               1391.0|                  186.5|                     74.62|           730.0800000000004|                    245.7000000000011|           23870.19999999996|                               13.75|         1.1612903225806452|        5.585108695652177|\n",
      "|          26|2020-01-01 00:00:00|       green|   27098.79000000005|              1743.25|                  221.5|        121.72999999999999|           551.2800000000002|                   292.50000000000233|           30034.89999999993|                                 0.0|         1.1054852320675106|        4.771315789473685|\n",
      "|         120|2020-01-01 00:00:00|       green|   692.4300000000001|                 5.25|                    7.0|        21.970000000000002|                       12.24|                    8.399999999999999|           752.7899999999998|                                 5.5|         1.1935483870967742|                4.6365625|\n",
      "+------------+-------------------+------------+--------------------+---------------------+-----------------------+--------------------------+----------------------------+-------------------------------------+----------------------------+------------------------------------+---------------------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the result to check it outselves...\n",
    "df_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ab0b9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9895"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count to see how many rows we have, must have a row for each locationid, month and service type combination\n",
    "df_result.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f67eeb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And write out the fie\n",
    "# Use coalesce, it's like partition, but to reduce partitions, so it'll reduce it to 1 partition\n",
    "df_result.coalesce(1).write.parquet('../../Data/data/module-05-batch/cloud-book/report/revenue', mode='overwrite')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataenginzoomvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
