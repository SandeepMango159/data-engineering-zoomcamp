id: postgres_taxi
namespace: de_zoomcamp

# General workflow will be
  # Make request to git repository and extract  data from github, 
  # Put into staging table where we can add unique id and filename as extra columns to the data, 
  # And then we merge the data into the main table so we ha ve a table that has everything inside of it, except for everything seperate... 

  
# Creates input with yellow or green taxis
inputs:
  - id: taxi
    type: SELECT
    displayName: Select taxi type
    values: ['yellow', 'green']
    defaults: 'yellow'

  # Input for year
  - id: year
    type: SELECT
    displayName: Select year
    values: ["2019", "2020"]
    defaults: "2019"

  # Input for months
  - id: month
    type: SELECT
    displayName: Select month
    values: ["01", "02", "03", "04", "05", "06", "07", "08", "09", "10", "11", "12"]
    defaults: "01"

variables:
  # File is the file we're downloading
  file: "{{inputs.taxi}}_tripdata_{{inputs.year}}-{{inputs.month}}.csv"
  # Staging is the table from the file, so with the monthly data
  staging_table: "public.{{inputs.taxi}}_tripdata_staging"
  # Table is the table that has all the data from all the years and months combined.
  table: "public.{{inputs.taxi}}_tripdata"
  # Data is the data that is created from the extract task
  data: "{{outputs.extract.outputFiles[inputs.taxi ~ '_tripdata_' ~ inputs.year ~ '-' ~ inputs.month ~ '.csv']}}"    
  

tasks:
  # Task to help us identify if this is a green or yellow taxi execution.
  - id: set_label
    type: io.kestra.plugin.core.execution.Labels
    labels:
      file: "{{render(vars.file)}}"
      taxi: "{{inputs.taxi}}"


  # Shell command that uses wget to get that file and unzips it, and creates a usable csv file
  - id: extract
    type: io.kestra.plugin.scripts.shell.Commands
    outputFiles:
      - "*.csv"
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    commands:
      - wget -qO- https://github.com/DataTalksClub/nyc-tlc-data/releases/download/{{inputs.taxi}}/{{render(vars.file)}}.gz | gunzip > {{render(vars.file)}}      

# Conditional statement to choose yellow or green table workflow, since both tables use slightly different schemas, thus cannot operate under the same condition
  - id: if_green
    type: io.kestra.plugin.core.flow.If
    condition: "{{ inputs.taxi == 'green' }}"
    then: 

    # Creates table with the same columns as expected from the green tripdata csv
    - id: green_create_table
      type: io.kestra.plugin.jdbc.postgresql.Queries
      sql: |
        CREATE TABLE IF NOT EXISTS {{render(vars.table)}} (
            unique_row_id          text,
            filename               text,
            VendorID               text,
            lpep_pickup_datetime   timestamp,
            lpep_dropoff_datetime  timestamp,
            store_and_fwd_flag     text,
            RatecodeID             text,
            PULocationID           text,
            DOLocationID           text,
            passenger_count        integer,
            trip_distance          double precision,
            fare_amount            double precision,
            extra                  double precision,
            mta_tax                double precision,
            tip_amount             double precision,
            tolls_amount           double precision,
            ehail_fee              double precision,
            improvement_surcharge  double precision,
            total_amount           double precision,
            payment_type           integer,
            trip_type              integer,
            congestion_surcharge   double precision
        );

    # Staging table used to create new columns to insert into real green table
    - id: green_create_staging_table
      type: io.kestra.plugin.jdbc.postgresql.Queries
      sql: |
        CREATE TABLE IF NOT EXISTS {{render(vars.staging_table)}} (
            unique_row_id          text,
            filename               text,
            VendorID               text,
            lpep_pickup_datetime   timestamp,
            lpep_dropoff_datetime  timestamp,
            store_and_fwd_flag     text,
            RatecodeID             text,
            PULocationID           text,
            DOLocationID           text,
            passenger_count        integer,
            trip_distance          double precision,
            fare_amount            double precision,
            extra                  double precision,
            mta_tax                double precision,
            tip_amount             double precision,
            tolls_amount           double precision,
            ehail_fee              double precision,
            improvement_surcharge  double precision,
            total_amount           double precision,
            payment_type           integer,
            trip_type              integer,
            congestion_surcharge   double precision
        );

    # Truncate staging table, meaning remove all rows from it
    # Not the same as dropping a table
    - id: green_truncate_staging_table
      type: io.kestra.plugin.jdbc.postgresql.Queries
      sql: |
        TRUNCATE TABLE {{render(vars.staging_table)}};      

    # Copies data into the staging table, from the data variable, from which we get the values, and we write to the columns specified in columns property
    # And specifices the table we write into
    - id: green_copy_in_to_staging_table
      type: io.kestra.plugin.jdbc.postgresql.CopyIn
      format: CSV
      from: "{{render(vars.data)}}"
      table: "{{render(vars.staging_table)}}"
      header: true
      columns: [VendorID,lpep_pickup_datetime,lpep_dropoff_datetime,store_and_fwd_flag,RatecodeID,PULocationID,DOLocationID,passenger_count,trip_distance,fare_amount,extra,mta_tax,tip_amount,tolls_amount,ehail_fee,improvement_surcharge,total_amount,payment_type,trip_type,congestion_surcharge]

    # Update de uniqe ids and filenames since they're null in staging table
    # Sets the unique_row_id column to a md5 hahs using values from the other rows, so on subsequent runs creates the same md5, not a random one
    - id: green_add_unique_id_and_filename
      type: io.kestra.plugin.jdbc.postgresql.Queries
      sql: |
        UPDATE {{render(vars.staging_table)}}
        SET 
          unique_row_id = md5(
            COALESCE(CAST(VendorID AS text), '') ||
            COALESCE(CAST(lpep_pickup_datetime AS text), '') || 
            COALESCE(CAST(lpep_dropoff_datetime AS text), '') || 
            COALESCE(PULocationID, '') || 
            COALESCE(DOLocationID, '') || 
            COALESCE(CAST(fare_amount AS text), '') || 
            COALESCE(CAST(trip_distance AS text), '')      
          ),
          filename = '{{render(vars.file)}}';

    # Merge the staging able into the actual trip data table
    # On unique row id, so only merges it when it's not in the table
    # Meaning no duplicates will be added from the staging into the green table
    - id: green_merge_data
      type: io.kestra.plugin.jdbc.postgresql.Queries
      sql: |
        MERGE INTO {{render(vars.table)}} AS T
        USING {{render(vars.staging_table)}} AS S
        ON T.unique_row_id = S.unique_row_id
        WHEN NOT MATCHED THEN
          INSERT (
            unique_row_id, filename, VendorID, lpep_pickup_datetime, lpep_dropoff_datetime,
            store_and_fwd_flag, RatecodeID, PULocationID, DOLocationID, passenger_count,
            trip_distance, fare_amount, extra, mta_tax, tip_amount, tolls_amount, ehail_fee,
            improvement_surcharge, total_amount, payment_type, trip_type, congestion_surcharge
          )
          VALUES (
            S.unique_row_id, S.filename, S.VendorID, S.lpep_pickup_datetime, S.lpep_dropoff_datetime,
            S.store_and_fwd_flag, S.RatecodeID, S.PULocationID, S.DOLocationID, S.passenger_count,
            S.trip_distance, S.fare_amount, S.extra, S.mta_tax, S.tip_amount, S.tolls_amount, S.ehail_fee,
            S.improvement_surcharge, S.total_amount, S.payment_type, S.trip_type, S.congestion_surcharge
          );

  # Task to purge files from the output for the current execution, 
  # like the csv files we're downloading, so they're deleted
  # disabeld to true if you want to actually explore them... 
  - id: purge_files
    type: io.kestra.plugin.core.storage.PurgeCurrentExecutionFiles
    description: This will remove output files. If you'd like to explore Kestra outputs, disable it.
    disabled: false


# PluginDefaults tell tasks to use these values for their types, so these blocks don't have to be copy pasted everywhere all the time
pluginDefaults:
  - type: io.kestra.plugin.jdbc.postgresql
    values:
      url: jdbc:postgresql://host.docker.internal:5432/postgres-zoomcamp
      username: kestra
      password: k3str4
